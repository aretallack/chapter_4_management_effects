---
title: "Final Models"
format: html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, sf, gstat, mgcv, mgcViz, gratia, data.table, lubridate)

# plotting function using mgcViz
# fast way to quickly visualize all terms, including parametric
fn_viz <- function(mod){
  getViz(mod) %>% 
    plot(allTerms = T) %>%
    print(pages = 1)
} 

# Plotting functoin using gratia
fn_viz_1 <- function(mod, smooth_term){
  # get xvariable name
  xvar <- str_remove(smooth_term, "s\\(") %>% 
    str_remove(., "\\)")
  
  p_out <- gratia::smooth_estimates(mod) %>% 
    filter(smooth == smooth_term) %>% 
    # pivot_longer(cols=c(est,se,month)) %>% 
    ggplot(aes( !!ensym(xvar), est)) +
    geom_ribbon(aes(!!ensym(xvar), 
                    ymax = est + 1.96 * se, # assuming an "identity" link
                    ymin = est - 1.96 * se), 
                alpha = 0.5, 
                lty = 0) +
    geom_line() +
    labs(x = xvar,
         y = "Partial Effect") +
    coord_cartesian(expand = F) +
    theme_linedraw() +
    theme(panel.grid = element_blank(),
          text = element_text(size = 18))
  
  return(p_out)
}

fn_viz_stations <- function(mod) {
  vec_sm2 <- smooths(mod)
  gratia::smooth_estimates(mod) %>%
    filter(smooth %in% vec_sm2[2:32]) %>%
    ggplot(aes(ddate, est, color = station)) +
    # geom_ribbon(aes(!!ensym(xvar),
    #                 ymax=est+1.96*se, # assuming an "identity" link
    #                 ymin=est-1.96*se),
    #             alpha=0.5,
    #             lty=0)+
    geom_line(
      aes(group = station),
      lwd = 1.5,
      color = 'black'
    ) +
    geom_line() +
    geom_line(
      data = . %>%
        filter(station == 'Bon Bon'),
      lwd = 2,
      col = 'red'
    ) +
    labs(x = "Date",
         y = "Partial Effect") +
    scale_color_viridis_d(option = 'H') +
    coord_cartesian(expand = F) +
    theme_linedraw() +
    theme(panel.grid = element_blank())
}

fn_validate <- function(testData, mod) {
  
tmp_pred <- testData %>% 
  mutate(pred = predict(mod, newdata=., type='response'))

metrica::R2(obs = tmp_pred$pv,
            pred = tmp_pred$pred) %>% 
  print()
metrica::RMSE(obs = tmp_pred$pv,
              pred = tmp_pred$pred) %>% 
  print()
  
}
```

# Import data

```{r}
DF <- read_rds("./RasterVariables/RasterDF.rds") %>%
  filter(!is.na(p_img_3)) %>%
  filter(!is.na(p_img_12)) %>%
# filter(!is.na(p_img_24)) %>%
# filter(!is.na(p_img_36)) %>%
  filter(is.na(water)) %>%
  filter(is.na(fence_buffer)) %>%
  # filter(dog_fence == 1) %>%
  filter(!station %in% c("Lake Torrens NP", "Other", "Kati Thanda-Lake Eyre NP", "Lake Gairdner NP", "Salt Lake", "Lake Everard", "Coward Springs Railway Siding", "Coober Pedy Commonage", "Wadma Kadarbu Mound Springs CP", "Olympic Dam")) %>%
  filter(!nvis_group %in% c("Inland aquatic - freshwater, salt lakes, lagoons", "Naturally bare - sand, rock, claypan, mudflat", "Unclassified native vegetation", "Eucalypt Open Woodlands", "Other Grasslands, Herblands, Sedgelands and Rushlands", "Other Shrublands")) %>%
  as.data.table()

DF <- DF %>%
  mutate(ddate = decimal_date(as_date(date)),
         fcell = as.factor(cell),
         month = month(as_date(date))
         )

DF$nvis_group <- droplevels(DF$nvis_group)
DF$station <- as.factor(DF$station)

DF$stocked[which(is.na(DF$stocked))] <- 1
DF$stocked <- as.factor(DF$stocked)

# Set all NA tsd to 0 (assumes all stations are stocked)
DF$tsd[which(is.na(DF$tsd))] <- 0

# Create separate filtered DF just with Bon Bon and surrounding areas (10 km buffer)
DFbb <- DF %>%
  filter(study_zone %in% c(1, 2))s
#
stocking_stations <- DF[which(!is.na(DF$stock_area)), "station"] %>%
  unique() %>%
  unlist() %>%
  as.character()

DFod <- DF %>% filter(station %in% stocking_stations)
#
# Remove stock from destocked stations
test <- DFod
curdimurka <- which(test$paddock == "Curdimurka" & test$year >= 2020) # index where paddock destocked
test[curdimurka, 3:8] <- 0 # Replace all stocking densities with 0

# For same years stocking densities must be calculated with an updated area
# (because curdimurka destocked, therefore remaining stock numbers must be concentrated)

# Save filtered DFs
write_rds(DF, "./RasterVariables/RasterDF_filtered.rds")
write_rds(DFbb, "./RasterVariables/RasterDFbb_filtered.rds")
write_rds(DFod, "./RasterVariables/RasterDFod_filtered.rds")

# read filtered RDS
# DF <- read_rds("./RasterVariables/RasterDF_filtered.rds")
# DFbb <- read_rds("./RasterVariables/RasterDFbb_filtered.rds")
# DFod <- read_rds("./RasterVariables/RasterDFod_filtered.rds")
```

# Select sample cells

```{r}
# Narrow scale
train_cells_bb <- DFbb[sample(.N, 1e6)]$cell %>% 
  unique() %>%
  sample(length(.) * 0.75)

test_cells_bb <- DFbb[sample(.N, 1e6)]$cell %>% 
  unique() %>% 
  .[which(!. %in% train_cells_bb)]

# Olympic dam analysis
train_cells_od <- DFod[sample(.N, 1e6)]$cell %>% 
  unique() %>%
  sample(length(.) * 0.75)

test_cells_od <- DFod[sample(.N, 1e6)]$cell %>% 
  unique() %>% 
  .[which(!. %in% train_cells_od)]

# Broad scale
# Get 10 random cell numbers for each station
train_cells <- DF[sample(.N, 1e6)]$cell %>% 
  unique() %>%
  sample(length(.) * 0.75)

test_cells <- DF[sample(.N, 1e6)]$cell %>% 
  unique() %>% 
  .[which(!. %in% train_cells)]

```

# Bon Bon Analysis

Analysis of Bon Bon and the area directly surrounding Bon Bon. Know more about the management at this particular region

models n(narrow)\_pv, n_npv, n_bare

https://stats.stackexchange.com/questions/401401/what-is-the-acceptable-level-of-concurvity

```{r eval = FALSE}
n_pv <- bam(pv ~
              tsd +
              s(ddate, bs = "ts") +
              s(month, bs = "cc") + # Rainfall dominated system, therefore maybe no need for temperature
              # s(tmean_3, k = 5) +
              # s(vpd_3, k = 5) + # Anomoly of vpd (?) probably not big impact
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
              # p_img_36 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DFbb[which(cell %in% train_cells_bb), ])

# concurvity(n_pv)
# summary(n_pv)
fn_viz(n_pv)
fn_validate(DFbb[which(cell %in% test_cells_bb), ], n_pv)

# fn_viz_1(n_pv, "s(ddate)")
# vec_sm <- gratia::smooths(n_pv)
# l_p <- lapply(vec_sm, fn_viz_1, mod = n_pv)
# patchwork::wrap_plots(l_p, ncol = 2)

n_npv <- bam(npv ~
              tsd +
              s(ddate, bs = "ts") +
              s(month, bs = "cc") +
              # s(tmean_3, k = 5) +
              # s(vpd_3, k = 5) +
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
              # p_img_36 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DFbb[which(cell %in% train_cells_bb), ])
  
# summary(n_npv)
fn_viz(n_npv)

fn_validate(DFbb[which(cell %in% test_cells_bb), ], n_npv)


n_bare <- bam(bare ~
              tsd +
              s(ddate, bs = "ts") +
              s(month, bs = "cc") +
              # s(tmean_3, k = 5) +
              # s(vpd_3, k = 5) +
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DFbb[which(cell %in% train_cells_bb), ])

# summary(n_bare)
fn_viz(n_bare)

fn_validate(DFbb[which(cell %in% test_cells_bb), ], n_bare)
```

# Olympic Dam Analysis

```{r}
od_pv <- bam(pv ~
              cattle_area + # possible smoothing function on stocking density
              s(ddate, bs = "ts") +
              s(month, bs = "cc") + # Rainfall dominated system, therefore maybe no need for temperature
              # s(tmean_3, k = 5) +
              # s(vpd_3, k = 5) + # Anomoly of vpd (?) probably not big impact
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
              # p_img_36 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DFod[which(cell %in% train_cells_od), ])

fn_viz(od_pv)
fn_validate(DFod[which(cell %in% test_cells_od), ], od_pv)

od_npv <- bam(npv ~
              cattle_area +
              s(ddate, bs = "ts") +
              s(month, bs = "cc") + # Rainfall dominated system, therefore maybe no need for temperature
              # s(tmean_3, k = 5) +
              # s(vpd_3, k = 5) + # Anomoly of vpd (?) probably not big impact
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
              # p_img_36 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DFod[which(cell %in% train_cells_od), ])

fn_viz(od_npv)

od_bare <- bam(bare ~
              cattle_area +
              s(ddate, bs = "ts") +
              s(month, bs = "cc") + # Rainfall dominated system, therefore maybe no need for temperature
              # s(tmean_3, k = 5) +
              # s(vpd_3, k = 5) + # Anomoly of vpd (?) probably not big impact
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
              # p_img_36 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DFod[which(cell %in% train_cells_od), ])

fn_viz(od_bare)
```

# Broad scale analysis

Analysis of wider region, looking at general drivers of change

models b(broad)\_pv, b_npv, b_bare

## GAMs

```{r eval = FALSE}
b_pv <- bam(pv ~
              te(x, y, fx = T, k = 10) +
              s(ddate, by = station, bs = "fs") +
              s(month, bs = "cc") +
              # s(tmean_3, k = 5) +
              # s(vpd_3, k = 5) +
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DF[which(cell %in% sample_cells), ])
# concurvity(b_pv)
summary(b_pv)
fn_viz(b_pv)
fn_viz_stations(b_pv)

b_npv <- bam(npv ~
              te(x, y, fx = T, k = 10) +
              s(ddate, by = station, bs = "bs") +
              s(month, bs = "cc") +
              s(tmean_3, k = 5) +
              s(vpd_3, k = 5) +
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DF[which(cell %in% sample_cells), ])

fn_viz(b_npv)
fn_viz_stations(b_npv)

b_bare <- bam(bare ~
              te(x, y, fx = T, k = 10) +
              s(ddate, by = station, bs = "bs") +
              s(month, bs = "cc") +
              s(tmean_3, k = 5) +
              s(vpd_3, k = 5) +
              p_img_3 * nvis_group +
              p_img_12 * nvis_group,
            method = "fREML",
            discrete = T,
            data = DF[which(cell %in% sample_cells), ])

fn_viz(bare)
```

## Anomaly-based regression

```{r}
# sample dataset
ss <- DF[which(cell %in% train_cells), ]

ref_year <- 2009 # Year that referece means will be calculated before

# Calculate "climatology" or monthly means, and SD of PV per month across years
# Mean and standard deviation per location per month 
# Creates reference values from pre-2009
ss_refs <- ss[ddate < ref_year][,.(pv_u = mean(pv,na.rm = T), 
                               pv_sd = sd(pv,na.rm = T),
                               npv_u = mean(npv, na.rm = T),
                               npv_sd = sd(pv, na.rm = T),
                               bare_u = mean(bare, na.rm = T),
                               bare_sd = sd(bare, na.rm = T)), by = .(x, y, month)]

# Add these summary stats to original dataset
ss <- merge(ss, ss_refs, by = c("x", "y", "month"))

# calculation of anomalies, and z-score transformed anomalies
# Differece of each pv value to the mean pv value for that cell and month (calculated before 2009)
ss[,`:=`(pv_anom = pv - pv_u)] # abs anomaly, by month
ss[,`:=`(pv_anom_sd = pv_anom/pv_sd)] # z-score transformed anomaly
ss[,`:=`(npv_anom = npv - npv_u)]
ss[,`:=`(npv_anom_sd = npv_anom/npv_sd)]
ss[,`:=`(bare_anom = bare - bare_u)]
ss[,`:=`(bare_anom_sd = bare_anom/bare_sd)]

# aggregration to year per pixel, for min/avg/max of pv_anom
# i.e. per cycle minimum, maximum and mean (annual cycles)
ss2 <- ss[,.(pv_anom_min = min(pv_anom, na.rm = T),
           pv_anom_avg = mean(pv_anom, na.rm = T),
           pv_anom_max = max(pv_anom, na.rm = T),
           npv_anom_min = min(npv_anom, na.rm = T),
           npv_anom_avg = mean(npv_anom, na.rm = T),
           npv_anom_max = max(npv_anom, na.rm = T),
           bare_anom_min = min(bare_anom, na.rm = T),
           bare_anom_avg = mean(bare_anom, na.rm = T),
           bare_anom_max = max(bare_anom, na.rm = T)), 
        by = .(x, y, station, nvis_group, ibra_subregion, year)] %>% 
  filter(year >= ref_year)


#################################################################
### Function to plot trend of selected stations cover anomaly ###
#################################################################

# visualize trends of anoms
# Plots increase in average, max and minimum anomolies
compare_stations <- function(stations, cover_type){
  data <- ss2 %>% 
    select(year, station,starts_with(cover_type)) %>% 
    pivot_longer(-c("year","station"))
  
  
    ggplot(data, aes(year,value, group = station)) +
    geom_smooth(method = 'lm', se = F, col = 'grey', lwd = 0.5) +
    geom_smooth(data = data %>% 
                  filter(station %in% stations), 
                method = 'lm', se = F,
                aes(colour = station),
                lwd = 2) + 
    facet_wrap(~name, dir = "h")
}


###################################################################
### Function to compare stations pre-reference cover percentage ###
###################################################################

compare_refs <- function(stations) {
  data <- ss %>% 
    select(year, station, nvis_group, pv_u) %>% 
    filter(year < 2009) %>%
    group_by(station) %>% 
    summarise(mean = mean(pv_u), .groups = "keep") %>% 
    arrange(mean)

  
  ggplot(data, aes(reorder(station, mean), mean)) +
    geom_bar(stat = "identity", fill = "grey70") +
    geom_bar(data = data %>% filter(station %in% stations), stat = "identity", aes(fill = station)) +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
    )
}


####################################################################################
### Compare stations pre-reference mean cover to post-reference anomaly response ###
####################################################################################

dat <- ss2 %>%
    select(year, station, starts_with(c("pv", "npv", "bare"))) %>%
    pivot_longer(-c("year","station"))
  
# Initial tibble for intercepts to go into
intercepts <- tibble(station = rep(unique(dat$station), each = 9),
                     name = rep(unique(dat$name), times = length(unique(dat$station))),
                     intercept = as.numeric(NA))

for (n in 1:9) {
  for (i in 1:length(unique(dat$station))) {
    dat2 <- dat %>% 
      filter(station == unique(.$station)[i]) %>% 
      filter(name == unique(dat$name)[n]) %>% 
      filter(!is.na(value)) %>% 
      filter(!is.infinite(value))
    
    lm <- lm(value ~ year, data = dat2) 
    
    intercepts$intercept[which(intercepts$station == unique(dat$station)[i] & intercepts$name == unique(dat$name)[n])] <- summary(lm)$coefficients[2, 1]
    # print(i)
    }
  }
    
data <- ss %>% 
  select(year, station, pv, npv, bare) %>% 
  filter(year < 2009) %>%
  pivot_longer(-c("year", "station")) %>% 
  group_by(station, name) %>%
  summarise(pre2009_mean = mean(value, na.rm = T), .groups = "keep") %>% 
  rename("cover" = "name")

get_cover <- function(x) str_split(x, "_", simplify = T)[,1]

intercepts <- intercepts %>% 
  mutate(cover = get_cover(name), .after = 2)

intercepts <- merge(intercepts, data, by = c("station", "cover"))


response_vs_ref <- function(stations, cover_type) {
  ggplot(intercepts %>% 
           filter(cover == cover_type), 
         aes(x = pre2009_mean, y = intercept)) +
    geom_point() +
    geom_point(data = intercepts %>% 
                 filter(cover == cover_type) %>% 
                 filter(station %in% stations),
               aes(colour = station),
               size = 3) +
    facet_wrap(~name, dir = "v")
}

compare_stations("Bon Bon", "pv")

compare_stations(c("Yellabinna RR", "Wilgena", "Mulgathing", "Mobella"), "pv")
compare_stations(c("Bon Bon", "Mount Eba", "Coondambo", "North Well", "Mount Vivian"), "pv")
response_vs_ref(c("Bon Bon", "Mount Eba", "Coondambo", "North Well", "Mount Vivian"), "bare")
```

## reconstructing the predictions

```{r}
# 
# # 'simple' linear model of 
# jj1 <- gam(I(pv_anom_max + 10) ~ 
#              # te(x,y)+
#              # s(nvis_group, bs='re') + # random effect
#              year * station, 
#        data = ss2[year >= 2008], 
#        family = Gamma(link = 'log'))
# summary(jj1)

# library(visreg)
# visreg(jj1, xvar='year',by='station')

ss2 %>% select(x,y) %>% colMeans()

# simulate response to visualize the interaction of station with time

expand_grid(year = 2008:2022,
            station = ss$station %>% unique, 
            x = 558589.7,
            y = 6636685.1 ) %>% 
  mutate(pred = predict(jj1,newdata = ., type = 'response')) %>% 
  ggplot(data = .,aes(year, pred,color = station)) +
  geom_line(aes(group = station), col = 'black',lwd = 1) +
  geom_line() +
  geom_line(data = . %>%
              filter(station == "Yellabinna RR"),
            col = 'red',
            lwd = 2) +
  geom_line(data = . %>%
              filter(station == "Bon Bon"),
            col = 'blue',
            lwd = 2) +
  scale_color_viridis_d(option = 'H') +
  labs(y = "Estimated annual-max-PV anomaly trend")

length(coef(jj1)) # coefficients estimated from the model
dim(model.matrix(jj1)) # model matrix, is all of the covariates for each row, in matrix form

vec_jnk1 <- model.matrix(jj1) %*% coef(jj1) # matrix multiplication of covariates by coefficients
vec_jnk1 <- as.array(vec_jnk1[,1]) # cast to array

predict(jj1, type = 'response') == as.array(vec_jnk1) # the in-built prediction is equal to our manual reconstruction


ss[year %in% 2001:2008][,.(val = mean(pv,na.rm = T)),by = station][order(station)]
ss[year %in% 2020:2022][,.(val = mean(pv,na.rm = T)),by = station][order(station)]



# do geom line, overlay bb in different col. 
ss[,.(val = mean(pv,na.rm = T)), by = .(year,station)] %>% 
  ggplot(data = .,aes(year, val,group = station)) +
  geom_smooth(method = 'lm', 
              se = F, lwd = 0.5, col = 'grey60') +
  geom_smooth(method = 'lm',se = F,
            data = . %>% filter(station == "Yellabinna RR"), 
            col = 'red',lwd = 2) + 
  geom_smooth(method = 'lm',se = F,
            data = . %>% filter(station == "Bon Bon"), 
            col = 'green',lwd = 2) + 
  geom_smooth(method = 'lm',se = F,
            data = . %>% filter(station == "Coondambo"), 
            col = 'black',lwd = 2) + 
  geom_smooth(method = 'lm',se = F,
            data = . %>% filter(station == "Mount Eba"), 
            col = 'blue',lwd = 2) + 
  geom_smooth(method = 'lm',se = F,
            data = . %>% filter(station == "North Well"), 
            col = 'orange',lwd = 2)


ss[,.(val = pv), by = .(year,station)] %>% 
  ggplot(data = .,aes(year, val,group = station)) +
  geom_smooth(stat = "smooth",
              method = "gam",
              se = F, lwd = 0.5, col = 'grey60') +
  geom_smooth(data = ss2 %>% 
                select(year,station,starts_with(c('pv'))) %>% 
                pivot_longer(-c("year","station")) %>% 
                filter(station == "Yellabinna RR" & name == "pv_anom_max"),
              aes(year, value),
              col = 'red',
              method = 'lm',
              se = F) + 
  geom_smooth(stat = 'smooth',
              method = 'gam',
              se = F,
              data = . %>% filter(station == "Yellabinna RR"),
              col = 'red',lwd = 2)
  # geom_smooth(stat = 'smooth',se = F,
  #             data = . %>% filter(station == "Yellabinna RR"),
  #             col = 'red',lwd = 2) +
  # geom_smooth(method = 'lm',se = F,
  #             data = . %>% filter(station == "Bon Bon"), 
  #             col = 'green',lwd = 2) + 
  # geom_smooth(method = 'lm',se = F,
  #             data = . %>% filter(station == "Coondambo"), 
  #             col = 'black',lwd = 2) + 
  # geom_smooth(method = 'lm',se = F,
  #             data = . %>% filter(station == "Mount Eba"), 
  #             col = 'blue',lwd = 2) + 
  # geom_smooth(method = 'lm',se = F,
  #             data = . %>% filter(station == "North Well"), 
  #             col = 'orange',lwd = 2)



```
